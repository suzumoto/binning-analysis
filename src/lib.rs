extern crate num;
use num::Float;

#[derive(Debug, PartialEq)]
pub struct Accumulator<T: Float> {
    dataset: Vec<T>,
}

impl<T: Float>  Accumulator<T>
    where T: std::convert::From<u32> + std::fmt::Debug + std::convert::From<f64>
{
    pub fn new() -> Self {
        Self {
            dataset: Vec::new()
        }
    }
    
    pub fn push(&mut self, observable: T) {
        self.dataset.push(observable);
    }
    
    pub fn binning(self) -> Result<Analyzed<T>, String>{
        match self.dataset.len() {
            0 => Err("Dataset has no data".to_string()),
            num_sample => {
                let mut mean = self.dataset.iter().fold(num::zero::<T>(),|sum, value| sum + *value);
                let mut jackknife_bin = Vec::<T>::new();
                for index in 0 .. num_sample {
                    jackknife_bin.push((mean - self.dataset[index])/((num_sample - 1) as u32).into());
                }
                mean = mean / (num_sample as u32).into();
                let mut  error = jackknife_bin.iter().fold(num::zero::<T>(),|variance, value| variance + (*value - mean)*(*value - mean)) * ((num_sample - 1) as u32).into() / (num_sample as u32).into();
                let naive_error_square = self.dataset.iter().fold(num::zero::<T>(),|sum, value| sum + (*value - mean)*(*value - mean)) / ((num_sample - 1) as u32).into();
                let correlation_time = error / naive_error_square;
                error = error.sqrt();
                Ok(Analyzed::<T> {
                    mean,
                    error,
                    correlation_time,
                    number_of_inputs: num_sample as u32,
                    converged: false,
                })
            },
        }
    }
}                   
 
#[test]
fn test_binning(){
    let mut an = Accumulator::<f64>::new();
    an.push(1.0);
    an.push(0.0);
    an.push(-1.0);
    an.push(3.0);
    an.push(-3.0);
    let result = an.binning();
    let correct = Analyzed::<f64> {
        mean: 0.0,
        error: 1.0,
        correlation_time: 0.2,
        number_of_inputs: 5,
        converged: false,
    };
    assert_eq!(&result.unwrap(), &correct);
    
    let er = Accumulator::<f64>::new();
    let result_er = er.binning();
    assert_eq!(result_er.err(), Some("Dataset has no data".to_string()));

    let rand_box = [0.421142,0.348048,0.226837,0.299965,0.721473,0.798157,0.379698,0.0549193,0.762403,0.715973,0.0920296,0.194588,0.928139,0.759538,0.913298,0.219137,0.962948,0.463023,0.729386,0.547291,0.851841,0.881364,0.0512603,0.360628,0.134387,0.164313,0.975652,0.731023,0.967803,0.20686,0.998862,0.658234,0.624732,0.0893747,0.72217,0.292812,0.350122,0.529764,0.373859,0.260789,0.873207,0.785292,0.472116,0.045328,0.251649,0.659137,0.809721,0.30921,0.179314,0.0660684,0.293161,0.703321,0.248242,0.87601,0.196935,0.0894931,0.0959044,0.908928,0.177426,0.11863,0.272278,0.919013,0.440775,0.202723,0.547474,0.181255,0.884485,0.881806,0.524506,0.258902,0.804827,0.837688,0.32334,0.388804,0.151477,0.292162,0.709854,0.499748,0.197043,0.24683,0.970808,0.517485,0.38164,0.742871,0.042271,0.0257766,0.696043,0.298335,0.387317,0.385467,0.0620147,0.309793,0.353199,0.423878,0.404455,0.0980026,0.549838,0.0687393,0.292299,0.495793,0.552052,0.796222,0.626216,0.176093,0.570481,0.939248,0.858196,0.586376,0.745193,0.662299,0.865969,0.525317,0.688218,0.203955,0.0733877,0.762075,0.584584,0.140034,0.963201,0.0599535,0.161195,0.777575,0.724655,0.464992,0.785918,0.686629,0.525509,0.502266,0.394389,0.34961,0.717785,0.0743893,0.616613,0.65932,0.72817,0.987619,0.764869,0.835364,0.628966,0.404173,0.590595,0.070924,0.942316,0.428873,0.281854,0.880561,0.557298,0.198354,0.301685,0.538753,0.664746,0.978564,0.499997,0.146162,0.532717,0.597442,0.615935,0.68129,0.900721,0.518468,0.955702,0.522621,0.955551,0.875434,0.391161,0.953862,0.175782,0.564783,0.823872,0.264229,0.105979,0.850096,0.83723,0.247365,0.813315,0.117415,0.355553,0.52199,0.00980261,0.58831,0.869901,0.906752,0.543781,0.964874,0.72641,0.031538,0.3577,0.870349,0.682083,0.708534,0.828176,0.501045,0.800189,0.402417,0.892724,0.663191,0.706561,0.304003,0.190102,0.693568,0.757932,0.077223,0.0770435,0.556879,0.56757,0.390366,0.0555351,0.251099,0.602498,0.892594,0.792476,0.359944,0.0154104,0.699281,0.59593,0.438998,0.0468754,0.902791,0.000621943,0.0109994,0.224957,0.339612,0.529754,0.546652,0.541985,0.498974,0.877344,0.716836,0.138017,0.751508,0.547437,0.49578,0.20468,0.224508,0.789999,0.0991856,0.563608,0.143339,0.212464,0.198471,0.828561,0.349719,0.313422,0.0381895,0.344233,0.746088,0.922998,0.687358,0.374815,0.913161,0.884267,0.39391,0.604344,0.680822,0.78592,0.698773,0.189299,0.736067,0.988874,0.56425,0.784419,0.624313,0.188744,0.654847,0.369143,0.0523187,0.816056,0.501734,0.267454,0.452861,0.193197,0.742665,0.522438,0.407179,0.128317,0.434743,0.556059,0.667079,0.776822,0.851766,0.671664,0.877998,0.39244,0.382821,0.93426,0.640759,0.360718,0.635101,0.567776,0.346136,0.974168,0.105732,0.476848,0.150526,0.926093,0.17786,0.235463,0.567682,0.363971,0.00824447,0.816674,0.747326,0.303138,0.86876,0.823984,0.285213,0.5011,0.177622,0.0854659,0.196887,0.197966,0.879785,0.976786,0.108909,0.46256,0.117648,0.359286,0.202991,0.556509,0.26884,0.965217,0.505877,0.263782,0.166811,0.527638,0.000730144,0.681027,0.834902,0.964661,0.66905,0.2358,0.335932,0.921534,0.629459,0.286512,0.154812,0.848055,0.718559,0.993048,0.638996,0.772196,0.329498,0.810905,0.539265,0.608989,0.505532,0.345965,0.885277,0.704915,0.496606,0.0671365,0.00784706,0.58864,0.543575,0.434211,0.190109,0.718898,0.454028,0.787024,0.685249,0.855478,0.0230924,0.563202,0.129152,0.671545,0.81351,0.22666,0.512579,0.242271,0.222719,0.233083,0.917323,0.346608,0.18344,0.645614,0.526269,0.870065,0.212743,0.0321448,0.993395,0.853516,0.394302,0.0921748,0.447839,0.274669,0.530506,0.520789,0.521501,0.38635,0.993441,0.183309,0.513817,0.681418,0.285365,0.0597767,0.140236,0.26571,0.550916,0.65743,0.970257,0.373485,0.0622804,0.300043,0.520445,0.615101,0.0754782,0.292847,0.265378,0.309229,0.467252,0.354647,0.33609,0.576243,0.755712,0.349972,0.608695,0.684869,0.814493,0.41212,0.0637774,0.316959,0.398038,0.679514,0.0467892,0.688513,0.710936,0.731987,0.158323,0.453291,0.56874,0.297468,0.737425,0.694367,0.740071,0.0972211,0.140285,0.930626,0.183694,0.534977,0.802682,0.271524,0.500489,0.398174,0.920272,0.671363,0.0522809,0.0966254,0.566713,0.826874,0.243417,0.862959,0.989469,0.643842,0.344772,0.376493,0.577543,0.347965,0.0745228,0.183815,0.632067,0.316045,0.211885,0.279803,0.143791,0.0265808,0.124415,0.0931741,0.631824,0.942593,0.232174,0.905538,0.271448,0.0626507,0.115987,0.514543,0.781673,0.233736,0.178375,0.784276,0.118625,0.678793,0.585447,0.417959,0.329586,0.520954,0.302931,0.662599,0.223219,0.425824,0.314705,0.826858,0.0916545,0.860932,0.188718,0.552538,0.669203,0.865582,0.000502283,0.314553,0.132588,0.0100889,0.312297,0.587127,0.801571,0.567371,0.00718265,0.227789,0.337126,0.536735,0.855867,0.107865,0.776695,0.0543721,0.761628,0.933895,0.618802,0.757597,0.0126085,0.711798,0.277208,0.167209,0.908111,0.595966,0.248102,0.505209,0.570944,0.338206,0.727226,0.896067,0.232758,0.217869,0.204231,0.312905,0.101773,0.294945,0.0853368,0.107277,0.440969,0.206658,0.522282,0.788332,0.698142,0.398329,0.400542,0.106415,0.896382,0.229677,0.936174,0.459959,0.758483,0.870092,0.705819,0.281097,0.538277,0.295216,0.760956,0.43549,0.890755,0.916959,0.113694,0.164102,0.992322,0.843043,0.576508,0.502542,0.710061,0.204597,0.213919,0.377768,0.786143,0.0481233,0.122374,0.3891,0.378436,0.103503,0.875891,0.452682,0.753707,0.176611,0.752478,0.366911,0.723778,0.658551,0.319885,0.445261,0.348218,0.207815,0.701389,0.700088,0.509353,0.278573,0.886044,0.544769,0.560509,0.453078,0.153351,0.87816,0.76336,0.964645,0.200879,0.368071,0.393334,0.76573,0.0250916,0.848867,0.171674,0.686512,0.896864,0.031006,0.171291,0.511109,0.796942,0.106959,0.937747,0.386018,0.999242,0.510326,0.924568,0.0959845,0.344376,0.252224,0.919241,0.227387,0.663512,0.612646,0.160145,0.758226,0.900854,0.564833,0.511913,0.554511,0.404467,0.00653203,0.435653,0.0294529,0.243451,0.131609,0.178274,0.49658,0.00297139,0.643732,0.85275,0.672555,0.373284,0.390467,0.269459,0.454943,0.23911,0.370278,0.166447,0.0344693,0.9728,0.562359,0.602809,0.72608,0.797127,0.505866,0.263137,0.793832,0.217225,0.420358,0.194404,0.576869,0.124133,0.661836,0.975698,0.962443,0.658082,0.571971,0.977692,0.645092,0.577662,0.272691,0.835553,0.116681,0.768708,0.98013,0.658936,0.741926,0.976866,0.458628,0.277267,0.686041,0.454283,0.422873,0.306173,0.539348,0.880609,0.351586,0.814257,0.0152338,0.966516,0.611492,0.393219,0.448694,0.254461,0.955621,0.529575,0.390665,0.066125,0.213403,0.152157,0.719304,0.473421,0.269834,0.653694,0.389351,0.0107838,0.665873,0.66917,0.718324,0.936545,0.420579,0.625506,0.489456,0.485241,0.79438,0.686979,0.36856,0.211102,0.72449,0.693889,0.939279,0.824071,0.0269798,0.254722,0.305393,0.525895,0.207106,0.662738,0.58829,0.468685,0.544411,0.947283,0.061316,0.976527,0.936131,0.146966,0.768322,0.392182,0.324227,0.0867765,0.820465,0.166964,0.783283,0.347835,0.806514,0.0350244,0.0302193,0.282192,0.92632,0.22217,0.317772,0.0850442,0.102503,0.549629,0.037039,0.325933,0.851191,0.990299,0.4325,0.0169642,0.798821,0.0936561,0.0178699,0.481883,0.314147,0.914947,0.684802,0.359203,0.652595,0.486647,0.439868,0.794504,0.727539,0.978423,0.680677,0.616704,0.71501,0.971586,0.70928,0.540534,0.722385,0.152008,0.230436,0.961532,0.56368,0.56473,0.815191,0.530964,0.445648,0.661859,0.440888,0.45783,0.280113,0.801357,0.326288,0.102556,0.829898,0.0256838,0.422417,0.981247,0.31653,0.106804,0.698817,0.383185,0.683368,0.787081,0.934638,0.167415,0.710098,0.749208,0.530214,0.57479,0.896836,0.407686,0.935633,0.221969,0.448418,0.625034,0.618307,0.509276,0.779218,0.728282,0.853543,0.172048,0.919015,0.455424,0.650686,0.984954,0.549937,0.023169,0.726152,0.725913,0.592916,0.612266,0.580614,0.391831,0.531624,0.318391,0.411214,0.013497,0.559018,0.759918,0.297968,0.124729,0.615673,0.530481,0.768283,0.254912,0.0422793,0.0686869,0.230344,0.20496,0.318838,0.24494,0.5022,0.249647,0.135689,0.81928,0.865394,0.17192,0.4213,0.191659,0.651988,0.0160801,0.587362,0.871113,0.137892,0.101737,0.052024,0.00285775,0.429948,0.378158,0.695664,0.115091,0.175833,0.0562907,0.413515,0.762386,0.90674,0.00893689,0.522153,0.88228,0.770761,0.330884,0.130267,0.710492,0.68191,0.237093,0.237908,0.8578,0.781038,0.952961,0.312131,0.840297,0.151957,0.167216,0.21989,0.106453,0.0678503,0.559004,0.729869,0.313159,0.0299693,0.949491,0.363489,0.797323,0.817844,0.0850564,0.461853,0.705301,0.990089,0.315002,0.262999,0.922963,0.86673,0.541024,0.851316,0.718363,0.355019,0.684391,0.0997767,0.551642,0.262855,0.280717,0.573529,0.891054,0.368556,0.209134,0.11217,0.601414,0.586749,0.376816,0.00756437,0.0722568,0.870123,0.471127,0.273232,0.679295,0.155946,0.700422,0.361524,0.20442,0.933631,0.44956,0.522248,0.953255,0.655042,0.981076,0.489937,0.0895286,0.974415,0.263271,0.0594189,0.486279,0.776197,0.126996,0.382966,0.327596,0.46037,0.769771,0.377052,0.952675,0.91713,0.302718,0.524658,0.395732,0.0963597,0.502346,0.607721,0.349002,0.199827,0.298857,0.19974,0.814758,0.821173,0.635636,0.451679,0.806248,0.447098,0.421345,0.13882,0.570225,0.416695,0.463852,0.66775,0.702215,0.835886,0.572147,0.98846,0.437934,0.782965,0.29582,0.909194,0.459257,0.611715,0.691232,0.916475,0.373814];
    let mut an1 = Accumulator::<f64>::new();
    for i in rand_box.iter() {
        an1.push(*i);
    }
    let result1 = an1.binning();
    assert_eq!(result1.unwrap(), correct);
}    

#[test]
fn test_push(){
    let mut measurement = Accumulator::<f64> {
        dataset: Vec::new(),
    };
    measurement.push(1.0);
    measurement.push(2.0);
    
    let mut raw_vector = Vec::<f64>::new();
    raw_vector.push(1.0);
    raw_vector.push(2.0);
    
    let test_instance = Accumulator::<f64> {
        dataset: raw_vector,
    };
    assert_eq!(measurement, test_instance);
}

#[derive(Debug, PartialEq, Copy, Clone)]
pub struct Analyzed<T: Float + Copy> {
    mean: T,
    error: T,
    number_of_inputs: u32,
    correlation_time: T,
    converged: bool
}

use std::fmt;

impl<T: Float + Copy + fmt::Display> fmt::Display for Analyzed<T> {
    fn fmt(&self, dest: &mut fmt::Formatter) -> fmt::Result {
        write!(dest, "{} +- {}, tau: {} ......{} for {} entries",
               self.mean,
               self.error,
               self.correlation_time,
               if self.converged { "converged" } else { "NOT CONVERGED!!!"},
               self.number_of_inputs)
    }
}

#[test]
fn test_format() {
    let an = Analyzed::<f64> {
        mean: 12.1,
        error: 0.3,
        correlation_time: 1.1,
        number_of_inputs: 1024,
        converged: true,
    };
    assert_eq!(format!("{}",an), "12.1 +- 0.3, tau: 1.1 ......converged for 1024 entries");
}

use std::ops::*;
impl<T: Float> Add for Analyzed<T>
    where T: Add<Output=T>
{
    type Output = Self;
    fn add(self, rhs: Self) -> Self {
        Analyzed { mean: self.mean + rhs.mean,
                   error: (self.error * self.error + rhs.error * rhs.error).sqrt(),
                   number_of_inputs: self.number_of_inputs.min(rhs.number_of_inputs),
                   correlation_time: self.correlation_time.max(rhs.correlation_time),
                   converged: self.converged & rhs.converged,
        }
    }
}

impl<T: Float> Mul for Analyzed<T>
    where T: Mul<Output=T>
{
    type Output = Self;
    fn mul(self, rhs: Self) -> Self {
        Analyzed { mean: self.mean * rhs.mean,
                   error: {
                       let term1 = rhs.mean  * self.error;
                       let term2 = self.mean * rhs.error;
                       ((term1 * term1) + (term2 * term2)).sqrt()
                   },
                   number_of_inputs: self.number_of_inputs.min(rhs.number_of_inputs),
                   correlation_time: self.correlation_time.max(rhs.correlation_time),
                   converged: self.converged & rhs.converged,
        }
    }
}

impl<T: Float> Sub for Analyzed<T>
    where T: Sub<Output=T>
{
    type Output = Self;
    fn sub(self, rhs: Self) -> Self {
        Analyzed { mean: self.mean - rhs.mean,
                   error: (self.error * self.error + rhs.error * rhs.error).sqrt(),
                   number_of_inputs: self.number_of_inputs.min(rhs.number_of_inputs),
                   correlation_time: self.correlation_time.max(rhs.correlation_time),
                   converged: self.converged & rhs.converged,
        }
    }
}

impl<T: Float> Div for Analyzed<T>
    where T: Div<Output=T>
{
    type Output = Self;
    fn div(self, rhs: Self) -> Self {
        Analyzed { mean: self.mean / rhs.mean,
                   error: {
                       let term1 = self.error / rhs.mean;
                       let term2 = self.mean * rhs.error / rhs.mean / rhs.mean;
                       (term1 * term1 + term2 * term2).sqrt()
                   },
                   number_of_inputs: self.number_of_inputs.min(rhs.number_of_inputs),
                   correlation_time: self.correlation_time.max(rhs.correlation_time),
                   converged: self.converged & rhs.converged,
        }
    }
}

#[test]
fn test_operation(){
    let an1 = Analyzed::<f64> {
        mean: 1.0,
        error: 0.1,
        number_of_inputs: 1000,
        correlation_time: 1.0,
        converged: true,
    };
    let an2 = Analyzed::<f64> {
        mean: 2.0,
        error: 0.2,
        number_of_inputs: 1200,
        correlation_time: 2.0,
        converged: true,
    };
    let an3 = Analyzed::<f64> {
        mean: 3.0,
        error: (0.1*0.1 + 0.2*0.2).sqrt(),
        correlation_time: 2.0,
        number_of_inputs: 1000,
        converged: true,
    };
    let an4 = Analyzed::<f64> {
        mean: 2.0,
        error: (2.0*0.1*2.0*0.1 + 1.0*0.2*1.0*0.2).sqrt(),
        correlation_time: 2.0,
        number_of_inputs: 1000,
        converged: true,
    };
    let an5 = Analyzed::<f64> {
        mean: -1.0,
        error: (0.1*0.1 + 0.2*0.2).sqrt(),
        correlation_time: 2.0,
        number_of_inputs: 1000,
        converged: true,
    };
    let an6 = Analyzed::<f64> {
        mean: 0.5,
        error: (0.1*0.1/2.0/2.0 + 1.0*0.2*0.2/2.0/2.0/2.0/2.0).sqrt(),
        correlation_time: 2.0,
        number_of_inputs: 1000,
        converged: true,
    };
    assert_eq!(an3, an1 + an2);
    assert_eq!(an4, an1 * an2);
    assert_eq!(an5, an1 - an2);
    assert_eq!(an6, an1 / an2);
}
